{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:0\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:None\n",
      " | > fft_size:1024\n",
      " | > power:None\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:None\n",
      " | > signal_norm:None\n",
      " | > symmetric_norm:None\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:None\n",
      " | > pitch_fmin:None\n",
      " | > pitch_fmax:None\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:1.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " | > Found 278 files in C:\\TextToSpeech\\TTS\\rory\\dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " > Training Environment:\n",
      " | > Backend: Torch\n",
      " | > Mixed precision: False\n",
      " | > Precision: float32\n",
      " | > Current device: 0\n",
      " | > Num. of GPUs: 1\n",
      " | > Num. of CPUs: 20\n",
      " | > Num. of Torch Threads: 14\n",
      " | > Torch seed: 54321\n",
      " | > Torch CUDNN: True\n",
      " | > Torch CUDNN deterministic: False\n",
      " | > Torch CUDNN benchmark: False\n",
      " | > Torch TF32 MatMul: False\n",
      " > Start Tensorboard: tensorboard --logdir=c:\\TextToSpeech\\TTS\\rory\\outputs\\vits_ljspeech-June-01-2024_08+24PM-f1b64b72\n",
      "c:\\Users\\Rdgud\\miniconda3\\envs\\coqui\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\n",
      " > Model has 83059180 parameters\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 0/1\u001b[0m\n",
      " --> c:\\TextToSpeech\\TTS\\rory\\outputs\\vits_ljspeech-June-01-2024_08+24PM-f1b64b72\n",
      "\n",
      "\u001b[1m > TRAINING (2024-06-01 20:24:49) \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "> DataLoader initialization\n",
      "| > Tokenizer:\n",
      "\t| > add_blank: True\n",
      "\t| > use_eos_bos: False\n",
      "\t| > use_phonemes: True\n",
      "\t| > phonemizer:\n",
      "\t\t| > phoneme language: en-us\n",
      "\t\t| > phoneme backend: gruut\n",
      "| > Number of instances : 276\n",
      " | > Preprocessing samples\n",
      " | > Max text length: 174\n",
      " | > Min text length: 18\n",
      " | > Avg text length: 102.9963768115942\n",
      " | \n",
      " | > Max audio length: 222387.0\n",
      " | > Min audio length: 32691.0\n",
      " | > Avg audio length: 143258.884057971\n",
      " | > Num. instances discarded samples: 0\n",
      " | > Batch group size: 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rdgud\\miniconda3\\envs\\coqui\\lib\\site-packages\\torch\\functional.py:665: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
      "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\SpectralOps.cpp:878.)\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n",
      "c:\\Users\\Rdgud\\miniconda3\\envs\\coqui\\lib\\site-packages\\torch\\nn\\modules\\conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\cudnn\\Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "c:\\Users\\Rdgud\\miniconda3\\envs\\coqui\\lib\\site-packages\\torch\\autograd\\graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\cudnn\\Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-06-01 20:25:08 -- STEP: 0/276 -- GLOBAL_STEP: 0\u001b[0m\n",
      "     | > loss_disc: 6.085947036743164  (6.085947036743164)\n",
      "     | > loss_disc_real_0: 1.0116182565689087  (1.0116182565689087)\n",
      "     | > loss_disc_real_1: 1.0209587812423706  (1.0209587812423706)\n",
      "     | > loss_disc_real_2: 1.0361289978027344  (1.0361289978027344)\n",
      "     | > loss_disc_real_3: 0.9905913472175598  (0.9905913472175598)\n",
      "     | > loss_disc_real_4: 1.0160038471221924  (1.0160038471221924)\n",
      "     | > loss_disc_real_5: 1.0100728273391724  (1.0100728273391724)\n",
      "     | > loss_0: 6.085947036743164  (6.085947036743164)\n",
      "     | > grad_norm_0: tensor(6.7858, device='cuda:0')  (tensor(6.7858, device='cuda:0'))\n",
      "     | > loss_gen: 4.548264026641846  (4.548264026641846)\n",
      "     | > loss_kl: 197.15386962890625  (197.15386962890625)\n",
      "     | > loss_feat: 0.7026233673095703  (0.7026233673095703)\n",
      "     | > loss_mel: 107.08767700195312  (107.08767700195312)\n",
      "     | > loss_duration: 2.0965633392333984  (2.0965633392333984)\n",
      "     | > loss_1: 311.5889892578125  (311.5889892578125)\n",
      "     | > grad_norm_1: tensor(1949.5830, device='cuda:0')  (tensor(1949.5830, device='cuda:0'))\n",
      "     | > current_lr_0: 0.0002 \n",
      "     | > current_lr_1: 0.0002 \n",
      "     | > step_time: 2.1509  (2.1508991718292236)\n",
      "     | > loader_time: 16.2978  (16.29776120185852)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-06-01 20:25:21 -- STEP: 25/276 -- GLOBAL_STEP: 25\u001b[0m\n",
      "     | > loss_disc: 2.9923219680786133  (3.179781103134155)\n",
      "     | > loss_disc_real_0: 0.25968804955482483  (0.2743706920742989)\n",
      "     | > loss_disc_real_1: 0.2465374767780304  (0.28864984810352334)\n",
      "     | > loss_disc_real_2: 0.25292497873306274  (0.28926236033439634)\n",
      "     | > loss_disc_real_3: 0.23911228775978088  (0.29652135699987403)\n",
      "     | > loss_disc_real_4: 0.26420044898986816  (0.29966969430446627)\n",
      "     | > loss_disc_real_5: 0.2721312642097473  (0.30504737138748167)\n",
      "     | > loss_0: 2.9923219680786133  (3.179781103134155)\n",
      "     | > grad_norm_0: tensor(1.1100, device='cuda:0')  (tensor(2.1749, device='cuda:0'))\n",
      "     | > loss_gen: 1.6020898818969727  (1.6678762078285216)\n",
      "     | > loss_kl: 7.23142147064209  (23.225127201080323)\n",
      "     | > loss_feat: 0.46510377526283264  (0.32646104514598845)\n",
      "     | > loss_mel: 65.85628509521484  (68.116650390625)\n",
      "     | > loss_duration: 1.7614320516586304  (1.9020139408111572)\n",
      "     | > loss_1: 76.91632843017578  (95.23812896728515)\n",
      "     | > grad_norm_1: tensor(134.6994, device='cuda:0')  (tensor(241.2636, device='cuda:0'))\n",
      "     | > current_lr_0: 0.0002 \n",
      "     | > current_lr_1: 0.0002 \n",
      "     | > step_time: 0.4442  (0.4542971420288086)\n",
      "     | > loader_time: 0.0108  (0.0030223369598388673)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-06-01 20:25:31 -- STEP: 50/276 -- GLOBAL_STEP: 50\u001b[0m\n",
      "     | > loss_disc: 2.4317870140075684  (2.986785078048706)\n",
      "     | > loss_disc_real_0: 0.22129306197166443  (0.2616583769023418)\n",
      "     | > loss_disc_real_1: 0.25576168298721313  (0.2713158562779427)\n",
      "     | > loss_disc_real_2: 0.2272161990404129  (0.2681724101305008)\n",
      "     | > loss_disc_real_3: 0.08267699927091599  (0.27673173442482946)\n",
      "     | > loss_disc_real_4: 0.19560714066028595  (0.27842651173472416)\n",
      "     | > loss_disc_real_5: 0.10497201234102249  (0.26476831272244455)\n",
      "     | > loss_0: 2.4317870140075684  (2.986785078048706)\n",
      "     | > grad_norm_0: tensor(8.8510, device='cuda:0')  (tensor(7.0573, device='cuda:0'))\n",
      "     | > loss_gen: 2.0455455780029297  (1.81477166056633)\n",
      "     | > loss_kl: 6.408416271209717  (14.908399868011472)\n",
      "     | > loss_feat: 2.136305332183838  (0.9424842002987862)\n",
      "     | > loss_mel: 64.47036743164062  (66.95354713439941)\n",
      "     | > loss_duration: 1.9788895845413208  (1.857841215133667)\n",
      "     | > loss_1: 77.0395278930664  (86.4770443725586)\n",
      "     | > grad_norm_1: tensor(179.7537, device='cuda:0')  (tensor(201.6708, device='cuda:0'))\n",
      "     | > current_lr_0: 0.0002 \n",
      "     | > current_lr_1: 0.0002 \n",
      "     | > step_time: 0.3613  (0.4356765556335449)\n",
      "     | > loader_time: 0.001  (0.002675642967224122)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-06-01 20:25:42 -- STEP: 75/276 -- GLOBAL_STEP: 75\u001b[0m\n",
      "     | > loss_disc: 2.24733829498291  (2.7266510089238483)\n",
      "     | > loss_disc_real_0: 0.33804309368133545  (0.24563284307718278)\n",
      "     | > loss_disc_real_1: 0.11266525834798813  (0.2692501294612884)\n",
      "     | > loss_disc_real_2: 0.2759034037590027  (0.247601482073466)\n",
      "     | > loss_disc_real_3: 0.2500919997692108  (0.2541781414548556)\n",
      "     | > loss_disc_real_4: 0.07155410200357437  (0.2704272303978603)\n",
      "     | > loss_disc_real_5: 0.12187962234020233  (0.2345413681616386)\n",
      "     | > loss_0: 2.24733829498291  (2.7266510089238483)\n",
      "     | > grad_norm_0: tensor(20.0329, device='cuda:0')  (tensor(14.5722, device='cuda:0'))\n",
      "     | > loss_gen: 2.1478374004364014  (2.120613493124644)\n",
      "     | > loss_kl: 4.590937614440918  (11.40249465624491)\n",
      "     | > loss_feat: 2.9562065601348877  (1.9736890397469202)\n",
      "     | > loss_mel: 65.26250457763672  (64.98803115844726)\n",
      "     | > loss_duration: 1.7343050241470337  (1.8369839970270794)\n",
      "     | > loss_1: 76.69178771972656  (82.32181213378907)\n",
      "     | > grad_norm_1: tensor(209.6203, device='cuda:0')  (tensor(196.4048, device='cuda:0'))\n",
      "     | > current_lr_0: 0.0002 \n",
      "     | > current_lr_1: 0.0002 \n",
      "     | > step_time: 0.4479  (0.43605262756347657)\n",
      "     | > loader_time: 0.0027  (0.0026419480641682955)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-06-01 20:25:56 -- STEP: 100/276 -- GLOBAL_STEP: 100\u001b[0m\n",
      "     | > loss_disc: 1.5927547216415405  (2.622195597887039)\n",
      "     | > loss_disc_real_0: 0.08430075645446777  (0.23359789937734604)\n",
      "     | > loss_disc_real_1: 0.09408321231603622  (0.26117119632661345)\n",
      "     | > loss_disc_real_2: 0.06898557394742966  (0.24780342996120452)\n",
      "     | > loss_disc_real_3: 0.11415770649909973  (0.24996763713657852)\n",
      "     | > loss_disc_real_4: 0.09456579387187958  (0.25796294547617454)\n",
      "     | > loss_disc_real_5: 0.282555490732193  (0.247913353536278)\n",
      "     | > loss_0: 1.5927547216415405  (2.622195597887039)\n",
      "     | > grad_norm_0: tensor(44.9269, device='cuda:0')  (tensor(16.8467, device='cuda:0'))\n",
      "     | > loss_gen: 3.0738584995269775  (2.2627718609571454)\n",
      "     | > loss_kl: 3.8821287155151367  (9.582496359348294)\n",
      "     | > loss_feat: 8.750926971435547  (2.4704033149778852)\n",
      "     | > loss_mel: 56.59528732299805  (62.84856067657471)\n",
      "     | > loss_duration: 1.7474113702774048  (1.83222536444664)\n",
      "     | > loss_1: 74.04961395263672  (78.9964571762085)\n",
      "     | > grad_norm_1: tensor(157.2961, device='cuda:0')  (tensor(181.2769, device='cuda:0'))\n",
      "     | > current_lr_0: 0.0002 \n",
      "     | > current_lr_1: 0.0002 \n",
      "     | > step_time: 0.5484  (0.4617540645599365)\n",
      "     | > loader_time: 0.0037  (0.0031346654891967777)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-06-01 20:26:07 -- STEP: 125/276 -- GLOBAL_STEP: 125\u001b[0m\n",
      "     | > loss_disc: 1.4251152276992798  (2.5583190450668334)\n",
      "     | > loss_disc_real_0: 0.21762771904468536  (0.2500261091589927)\n",
      "     | > loss_disc_real_1: 0.014783862978219986  (0.2519919281601905)\n",
      "     | > loss_disc_real_2: 0.032181356102228165  (0.24281945842504501)\n",
      "     | > loss_disc_real_3: 0.30545684695243835  (0.24962157452106473)\n",
      "     | > loss_disc_real_4: 0.07567878812551498  (0.2451237798556687)\n",
      "     | > loss_disc_real_5: 0.12778767943382263  (0.24285469318926334)\n",
      "     | > loss_0: 1.4251152276992798  (2.5583190450668334)\n",
      "     | > grad_norm_0: tensor(28.4535, device='cuda:0')  (tensor(19.6757, device='cuda:0'))\n",
      "     | > loss_gen: 2.3212504386901855  (2.333194082736968)\n",
      "     | > loss_kl: 2.957446336746216  (8.281443517684929)\n",
      "     | > loss_feat: 5.963624000549316  (2.815642155766488)\n",
      "     | > loss_mel: 60.64435577392578  (62.351998809814454)\n",
      "     | > loss_duration: 1.8252793550491333  (1.8291848649978637)\n",
      "     | > loss_1: 73.71195983886719  (77.61146319580078)\n",
      "     | > grad_norm_1: tensor(168.1618, device='cuda:0')  (tensor(175.9424, device='cuda:0'))\n",
      "     | > current_lr_0: 0.0002 \n",
      "     | > current_lr_1: 0.0002 \n",
      "     | > step_time: 0.3884  (0.45488881874084475)\n",
      "     | > loader_time: 0.002  (0.003245151519775391)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-06-01 20:26:17 -- STEP: 150/276 -- GLOBAL_STEP: 150\u001b[0m\n",
      "     | > loss_disc: 2.5974810123443604  (2.5442352898915606)\n",
      "     | > loss_disc_real_0: 0.10138110816478729  (0.23928820903102546)\n",
      "     | > loss_disc_real_1: 0.2004186362028122  (0.2579550115019082)\n",
      "     | > loss_disc_real_2: 0.1779962182044983  (0.2506280582770706)\n",
      "     | > loss_disc_real_3: 0.21929216384887695  (0.2490422891328732)\n",
      "     | > loss_disc_real_4: 0.3042449653148651  (0.25332957419877256)\n",
      "     | > loss_disc_real_5: 0.406408429145813  (0.24963399405280748)\n",
      "     | > loss_0: 2.5974810123443604  (2.5442352898915606)\n",
      "     | > grad_norm_0: tensor(14.7045, device='cuda:0')  (tensor(22.0543, device='cuda:0'))\n",
      "     | > loss_gen: 1.4917051792144775  (2.3990693088372548)\n",
      "     | > loss_kl: 1.9351277351379395  (7.35245860576629)\n",
      "     | > loss_feat: 2.1118273735046387  (2.976181716223559)\n",
      "     | > loss_mel: 51.262046813964844  (61.519783147176106)\n",
      "     | > loss_duration: 1.8036043643951416  (1.8277871751785277)\n",
      "     | > loss_1: 58.604312896728516  (76.07527987162274)\n",
      "     | > grad_norm_1: tensor(123.9511, device='cuda:0')  (tensor(174.9861, device='cuda:0'))\n",
      "     | > current_lr_0: 0.0002 \n",
      "     | > current_lr_1: 0.0002 \n",
      "     | > step_time: 0.3837  (0.4482878255844116)\n",
      "     | > loader_time: 0.0008  (0.0030662266413370768)\n",
      "\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[WinError 32] The process cannot access the file because it is being used by another process: 'c:/TextToSpeech/TTS/rory/outputs/vits_ljspeech-June-01-2024_08+24PM-f1b64b72\\\\trainer_0_log.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Rdgud\\miniconda3\\envs\\coqui\\lib\\site-packages\\trainer\\trainer.py:1833\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1832\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1833\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1834\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mrank \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Rdgud\\miniconda3\\envs\\coqui\\lib\\site-packages\\trainer\\trainer.py:1785\u001b[0m, in \u001b[0;36mTrainer._fit\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1784\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip_train_epoch \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_with_eval:\n\u001b[1;32m-> 1785\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1786\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mrun_eval:\n",
      "File \u001b[1;32mc:\\Users\\Rdgud\\miniconda3\\envs\\coqui\\lib\\site-packages\\trainer\\trainer.py:1504\u001b[0m, in \u001b[0;36mTrainer.train_epoch\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1503\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cur_step, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loader):\n\u001b[1;32m-> 1504\u001b[0m     outputs, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_num_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcur_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloader_start_time\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1505\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m outputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Rdgud\\miniconda3\\envs\\coqui\\lib\\site-packages\\trainer\\trainer.py:1383\u001b[0m, in \u001b[0;36mTrainer.train_step\u001b[1;34m(self, batch, batch_n_steps, step, loader_start_time)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     scheduler \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscheduler[idx]\n\u001b[1;32m-> 1383\u001b[0m outputs, loss_dict_new, step_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1384\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1385\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1386\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1387\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1388\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1389\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1390\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1391\u001b[0m \u001b[43m    \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1392\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstep_optimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstep_optimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1393\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_optimizers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1394\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1395\u001b[0m \u001b[38;5;66;03m# skip the rest if the model returns None\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Rdgud\\miniconda3\\envs\\coqui\\lib\\site-packages\\trainer\\trainer.py:1226\u001b[0m, in \u001b[0;36mTrainer.optimize\u001b[1;34m(self, batch, model, optimizer, scaler, criterion, scheduler, config, optimizer_idx, step_optimizer, num_optimizers)\u001b[0m\n\u001b[0;32m   1225\u001b[0m \u001b[38;5;66;03m# forward pass and loss computation\u001b[39;00m\n\u001b[1;32m-> 1226\u001b[0m outputs, loss_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1227\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer_idx\u001b[49m\n\u001b[0;32m   1228\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1230\u001b[0m \u001b[38;5;66;03m# skip the rest if not outputs from the model\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Rdgud\\miniconda3\\envs\\coqui\\lib\\site-packages\\trainer\\trainer.py:1155\u001b[0m, in \u001b[0;36mTrainer._compute_loss\u001b[1;34m(self, batch, model, criterion, config, optimizer_idx)\u001b[0m\n\u001b[0;32m   1154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m optimizer_idx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1155\u001b[0m     outputs, loss_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model_train_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1156\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Rdgud\\miniconda3\\envs\\coqui\\lib\\site-packages\\trainer\\trainer.py:1116\u001b[0m, in \u001b[0;36mTrainer._model_train_step\u001b[1;34m(batch, model, criterion, optimizer_idx)\u001b[0m\n\u001b[0;32m   1115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\u001b[38;5;241m.\u001b[39mmodule\u001b[38;5;241m.\u001b[39mtrain_step(\u001b[38;5;241m*\u001b[39minput_args)\n\u001b[1;32m-> 1116\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Rdgud\\miniconda3\\envs\\coqui\\lib\\site-packages\\TTS\\tts\\models\\vits.py:1255\u001b[0m, in \u001b[0;36mVits.train_step\u001b[1;34m(self, batch, criterion, optimizer_idx)\u001b[0m\n\u001b[0;32m   1254\u001b[0m \u001b[38;5;66;03m# generator pass\u001b[39;00m\n\u001b[1;32m-> 1255\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_lenghts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1258\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1259\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspec_lens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1260\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwaveform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1261\u001b[0m \u001b[43m    \u001b[49m\u001b[43maux_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43md_vectors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43md_vectors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspeaker_ids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mspeaker_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlanguage_ids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage_ids\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1262\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1264\u001b[0m \u001b[38;5;66;03m# cache tensors for the generator pass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Rdgud\\miniconda3\\envs\\coqui\\lib\\site-packages\\TTS\\tts\\models\\vits.py:1027\u001b[0m, in \u001b[0;36mVits.forward\u001b[1;34m(self, x, x_lengths, y, y_lengths, waveform, aux_input)\u001b[0m\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;66;03m# duration predictor\u001b[39;00m\n\u001b[1;32m-> 1027\u001b[0m outputs, attn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_mas\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlang_emb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlang_emb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1029\u001b[0m \u001b[38;5;66;03m# expand prior\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Rdgud\\miniconda3\\envs\\coqui\\lib\\site-packages\\TTS\\tts\\models\\vits.py:919\u001b[0m, in \u001b[0;36mVits.forward_mas\u001b[1;34m(self, outputs, z_p, m_p, logs_p, x, x_mask, y_mask, g, lang_emb)\u001b[0m\n\u001b[0;32m    918\u001b[0m     logp \u001b[38;5;241m=\u001b[39m logp2 \u001b[38;5;241m+\u001b[39m logp3 \u001b[38;5;241m+\u001b[39m logp1 \u001b[38;5;241m+\u001b[39m logp4\n\u001b[1;32m--> 919\u001b[0m     attn \u001b[38;5;241m=\u001b[39m \u001b[43mmaximum_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mdetach()  \u001b[38;5;66;03m# [b, 1, t, t']\u001b[39;00m\n\u001b[0;32m    921\u001b[0m \u001b[38;5;66;03m# duration predictor\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Rdgud\\miniconda3\\envs\\coqui\\lib\\site-packages\\TTS\\tts\\utils\\helpers.py:175\u001b[0m, in \u001b[0;36mmaximum_path\u001b[1;34m(value, mask)\u001b[0m\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m maximum_path_cython(value, mask)\n\u001b[1;32m--> 175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmaximum_path_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Rdgud\\miniconda3\\envs\\coqui\\lib\\site-packages\\TTS\\tts\\utils\\helpers.py:226\u001b[0m, in \u001b[0;36mmaximum_path_numpy\u001b[1;34m(value, mask, max_neg_val)\u001b[0m\n\u001b[0;32m    225\u001b[0m     v \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(index_mask, v_max \u001b[38;5;241m+\u001b[39m value[:, :, j], max_neg_val)\n\u001b[1;32m--> 226\u001b[0m direction \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    228\u001b[0m path \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(value\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mwhere\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 1.03 MiB for an array with shape (1, 215, 629) and data type int64",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 84\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# init the trainer and 🚀\u001b[39;00m\n\u001b[0;32m     74\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m     75\u001b[0m     TrainerArgs(),\n\u001b[0;32m     76\u001b[0m     config,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     81\u001b[0m     \n\u001b[0;32m     82\u001b[0m )\n\u001b[1;32m---> 84\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m trainer\u001b[38;5;241m.\u001b[39msave_checkpoint()\n",
      "File \u001b[1;32mc:\\Users\\Rdgud\\miniconda3\\envs\\coqui\\lib\\site-packages\\trainer\\trainer.py:1860\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1858\u001b[0m         os\u001b[38;5;241m.\u001b[39m_exit(\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m-> 1860\u001b[0m     \u001b[43mremove_experiment_folder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1861\u001b[0m     traceback\u001b[38;5;241m.\u001b[39mprint_exc()\n\u001b[0;32m   1862\u001b[0m     sys\u001b[38;5;241m.\u001b[39mexit(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Rdgud\\miniconda3\\envs\\coqui\\lib\\site-packages\\trainer\\generic_utils.py:77\u001b[0m, in \u001b[0;36mremove_experiment_folder\u001b[1;34m(experiment_path)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m checkpoint_files:\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m fs\u001b[38;5;241m.\u001b[39mexists(experiment_path):\n\u001b[1;32m---> 77\u001b[0m         \u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiment_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     78\u001b[0m         logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m ! Run is removed from \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, experiment_path)\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Rdgud\\miniconda3\\envs\\coqui\\lib\\site-packages\\fsspec\\implementations\\local.py:179\u001b[0m, in \u001b[0;36mLocalFileSystem.rm\u001b[1;34m(self, path, recursive, maxdepth)\u001b[0m\n\u001b[0;32m    177\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m osp\u001b[38;5;241m.\u001b[39mabspath(p) \u001b[38;5;241m==\u001b[39m os\u001b[38;5;241m.\u001b[39mgetcwd():\n\u001b[0;32m    178\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot delete current working directory\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 179\u001b[0m     \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrmtree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    181\u001b[0m     os\u001b[38;5;241m.\u001b[39mremove(p)\n",
      "File \u001b[1;32mc:\\Users\\Rdgud\\miniconda3\\envs\\coqui\\lib\\shutil.py:759\u001b[0m, in \u001b[0;36mrmtree\u001b[1;34m(path, ignore_errors, onerror)\u001b[0m\n\u001b[0;32m    757\u001b[0m     \u001b[38;5;66;03m# can't continue even if onerror hook returns\u001b[39;00m\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 759\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_rmtree_unsafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43monerror\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Rdgud\\miniconda3\\envs\\coqui\\lib\\shutil.py:629\u001b[0m, in \u001b[0;36m_rmtree_unsafe\u001b[1;34m(path, onerror)\u001b[0m\n\u001b[0;32m    627\u001b[0m             os\u001b[38;5;241m.\u001b[39munlink(fullname)\n\u001b[0;32m    628\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m--> 629\u001b[0m             \u001b[43monerror\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munlink\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfullname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m     os\u001b[38;5;241m.\u001b[39mrmdir(path)\n",
      "File \u001b[1;32mc:\\Users\\Rdgud\\miniconda3\\envs\\coqui\\lib\\shutil.py:627\u001b[0m, in \u001b[0;36m_rmtree_unsafe\u001b[1;34m(path, onerror)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    626\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 627\u001b[0m         \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munlink\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfullname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m         onerror(os\u001b[38;5;241m.\u001b[39munlink, fullname, sys\u001b[38;5;241m.\u001b[39mexc_info())\n",
      "\u001b[1;31mPermissionError\u001b[0m: [WinError 32] The process cannot access the file because it is being used by another process: 'c:/TextToSpeech/TTS/rory/outputs/vits_ljspeech-June-01-2024_08+24PM-f1b64b72\\\\trainer_0_log.txt'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from trainer import Trainer, TrainerArgs\n",
    "\n",
    "from TTS.tts.configs.shared_configs import BaseDatasetConfig\n",
    "from TTS.tts.configs.vits_config import VitsConfig\n",
    "from TTS.tts.datasets import load_tts_samples\n",
    "from TTS.tts.models.vits import Vits, VitsAudioConfig\n",
    "from TTS.tts.utils.text.tokenizer import TTSTokenizer\n",
    "from TTS.utils.audio import AudioProcessor\n",
    "from multiprocessing import freeze_support\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  freeze_support()\n",
    "  \n",
    "  output_path = os.path.dirname(os.path.abspath(\"outputs/outputs.json\"))\n",
    "  dataset_config = BaseDatasetConfig(\n",
    "      formatter=\"ljspeech\", meta_file_train=\"metadata.csv\", path=os.path.join(output_path, \"../dataset/\")\n",
    "  )\n",
    "  audio_config = VitsAudioConfig(\n",
    "      sample_rate=22050, win_length=1024, hop_length=256, num_mels=80, mel_fmin=0, mel_fmax=None\n",
    "  )\n",
    "\n",
    "  config = VitsConfig(\n",
    "      audio=audio_config,\n",
    "      run_name=\"vits_ljspeech\",\n",
    "      batch_size=1,\n",
    "      eval_batch_size=16,\n",
    "      batch_group_size=1,\n",
    "      num_loader_workers=2,\n",
    "      num_eval_loader_workers=4,\n",
    "      run_eval=True,\n",
    "      test_delay_epochs=-1,\n",
    "      epochs=1,\n",
    "      text_cleaner=\"english_cleaners\",\n",
    "      use_phonemes=True,\n",
    "      phoneme_language=\"en-us\",\n",
    "      phoneme_cache_path=os.path.join(output_path, \"phoneme_cache\"),\n",
    "      compute_input_seq_cache=True,\n",
    "      print_step=25,\n",
    "      print_eval=True,\n",
    "      mixed_precision=False,\n",
    "      output_path=output_path,\n",
    "      datasets=[dataset_config],\n",
    "      cudnn_benchmark=False,\n",
    "  )\n",
    "\n",
    "  # INITIALIZE THE AUDIO PROCESSOR\n",
    "  # Audio processor is used for feature extraction and audio I/O.\n",
    "  # It mainly serves to the dataloader and the training loggers.\n",
    "  ap = AudioProcessor.init_from_config(config)\n",
    "\n",
    "  # INITIALIZE THE TOKENIZER\n",
    "  # Tokenizer is used to convert text to sequences of token IDs.\n",
    "  # config is updated with the default characters if not defined in the config.\n",
    "  tokenizer, config = TTSTokenizer.init_from_config(config)\n",
    "\n",
    "  # LOAD DATA SAMPLES\n",
    "  # Each sample is a list of ```[text, audio_file_path, speaker_name]```\n",
    "  # You can define your custom sample loader returning the list of samples.\n",
    "  # Or define your custom formatter and pass it to the `load_tts_samples`.\n",
    "  # Check `TTS.tts.datasets.load_tts_samples` for more details.\n",
    "  train_samples, eval_samples = load_tts_samples(\n",
    "      dataset_config,\n",
    "      eval_split=True,\n",
    "      eval_split_max_size=config.eval_split_max_size,\n",
    "      eval_split_size=config.eval_split_size,\n",
    "  )\n",
    "\n",
    "  # init model\n",
    "  model = Vits(config, ap, tokenizer, speaker_manager=None)\n",
    "\n",
    "  # init the trainer and 🚀\n",
    "  trainer = Trainer(\n",
    "      TrainerArgs(),\n",
    "      config,\n",
    "      output_path,\n",
    "      model=model,\n",
    "      train_samples=train_samples,\n",
    "      eval_samples=eval_samples,\n",
    "      \n",
    "  )\n",
    "\n",
    "  trainer.fit()\n",
    "\n",
    "  trainer.save_checkpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coqui",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
