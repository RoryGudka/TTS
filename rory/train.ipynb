{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from trainer import Trainer, TrainerArgs\n",
    "\n",
    "from TTS.tts.configs.shared_configs import BaseDatasetConfig\n",
    "from TTS.tts.configs.vits_config import VitsConfig\n",
    "from TTS.tts.datasets import load_tts_samples\n",
    "from TTS.tts.models.vits import Vits, VitsAudioConfig\n",
    "from TTS.tts.utils.text.tokenizer import TTSTokenizer\n",
    "from TTS.utils.audio import AudioProcessor\n",
    "import time\n",
    "from multiprocessing import freeze_support\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  freeze_support()\n",
    "  \n",
    "  output_path = os.path.dirname(os.path.abspath(\"outputs/outputs.json\"))\n",
    "  dataset_config = BaseDatasetConfig(\n",
    "      formatter=\"ljspeech\", meta_file_train=\"metadata.csv\", path=os.path.join(output_path, \"../dataset/\")\n",
    "  )\n",
    "  audio_config = VitsAudioConfig(\n",
    "      sample_rate=22050, win_length=1024, hop_length=256, num_mels=80, mel_fmin=0, mel_fmax=None\n",
    "  )\n",
    "\n",
    "  config = VitsConfig(\n",
    "      audio=audio_config,\n",
    "      run_name=\"vits_ljspeech\",\n",
    "      batch_size=1,\n",
    "      eval_batch_size=16,\n",
    "      batch_group_size=1,\n",
    "      num_loader_workers=8,\n",
    "      num_eval_loader_workers=4,\n",
    "      run_eval=True,\n",
    "      test_delay_epochs=-1,\n",
    "      epochs=10,\n",
    "      text_cleaner=\"english_cleaners\",\n",
    "      use_phonemes=True,\n",
    "      phoneme_language=\"en-us\",\n",
    "      phoneme_cache_path=os.path.join(output_path, \"phoneme_cache\"),\n",
    "      compute_input_seq_cache=True,\n",
    "      print_step=25,\n",
    "      print_eval=True,\n",
    "      mixed_precision=False,\n",
    "      output_path=output_path,\n",
    "      datasets=[dataset_config],\n",
    "      cudnn_benchmark=False,\n",
    "  )\n",
    "\n",
    "  # INITIALIZE THE AUDIO PROCESSOR\n",
    "  # Audio processor is used for feature extraction and audio I/O.\n",
    "  # It mainly serves to the dataloader and the training loggers.\n",
    "  ap = AudioProcessor.init_from_config(config)\n",
    "\n",
    "  # INITIALIZE THE TOKENIZER\n",
    "  # Tokenizer is used to convert text to sequences of token IDs.\n",
    "  # config is updated with the default characters if not defined in the config.\n",
    "  tokenizer, config = TTSTokenizer.init_from_config(config)\n",
    "\n",
    "  # LOAD DATA SAMPLES\n",
    "  # Each sample is a list of ```[text, audio_file_path, speaker_name]```\n",
    "  # You can define your custom sample loader returning the list of samples.\n",
    "  # Or define your custom formatter and pass it to the `load_tts_samples`.\n",
    "  # Check `TTS.tts.datasets.load_tts_samples` for more details.\n",
    "  train_samples, eval_samples = load_tts_samples(\n",
    "      dataset_config,\n",
    "      eval_split=True,\n",
    "      eval_split_max_size=config.eval_split_max_size,\n",
    "      eval_split_size=config.eval_split_size,\n",
    "  )\n",
    "\n",
    "  # init model\n",
    "  model = Vits(config, ap, tokenizer, speaker_manager=None)\n",
    "\n",
    "  # init the trainer and ðŸš€\n",
    "  trainer = Trainer(\n",
    "      TrainerArgs(),\n",
    "      config,\n",
    "      output_path,\n",
    "      model=model,\n",
    "      train_samples=train_samples,\n",
    "      eval_samples=eval_samples,\n",
    "      \n",
    "  )\n",
    "\n",
    "  trainer.fit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coqui",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
